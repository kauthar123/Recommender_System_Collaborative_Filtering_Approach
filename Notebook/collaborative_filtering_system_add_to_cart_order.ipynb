{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PV15DLVWYPbN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "J0an7w7-Ydc8",
    "outputId": "bc2a27cf-86e5-4c87-ca5c-eb2d9ea788e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9350846,\n        \"min\": 7248,\n        \"max\": 32387189,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          22734282,\n          17735617,\n          6226520\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 986027,\n        \"min\": 747,\n        \"max\": 3416175,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          2397877,\n          1870478,\n          657179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14006,\n        \"min\": 45,\n        \"max\": 49683,\n        \"num_unique_values\": 776,\n        \"samples\": [\n          12732,\n          6438,\n          31608\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"add_to_cart_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1,\n        \"max\": 65,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          65,\n          30,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reordered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59798,\n        \"min\": 125,\n        \"max\": 206047,\n        \"num_unique_values\": 997,\n        \"samples\": [\n          13701,\n          195721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prior\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 1,\n        \"max\": 97,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_dow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_hour_of_day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 23,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"days_since_prior_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.073551822190653,\n        \"min\": 0.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          28.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 776,\n        \"samples\": [\n          \"Organic Ground Turkey\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aisle_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 2,\n        \"max\": 131,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aisle\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"latino foods\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"frozen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ac45a1c5-961c-4f54-8e2c-65d4d5243056\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22678753</td>\n",
       "      <td>2392060</td>\n",
       "      <td>2604</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>51072</td>\n",
       "      <td>prior</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lemon Zest Sorbetto</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>ice cream ice</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13346427</td>\n",
       "      <td>1408550</td>\n",
       "      <td>34243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25449</td>\n",
       "      <td>prior</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Organic Baby Broccoli</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22925325</td>\n",
       "      <td>2418006</td>\n",
       "      <td>21616</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>138390</td>\n",
       "      <td>prior</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Organic Baby Arugula</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17216127</td>\n",
       "      <td>1816124</td>\n",
       "      <td>43209</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42441</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large Eggs</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>eggs</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30363018</td>\n",
       "      <td>3202917</td>\n",
       "      <td>43368</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81257</td>\n",
       "      <td>prior</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Wild Salmon Florentine Cat Food</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>cat food care</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac45a1c5-961c-4f54-8e2c-65d4d5243056')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ac45a1c5-961c-4f54-8e2c-65d4d5243056 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ac45a1c5-961c-4f54-8e2c-65d4d5243056');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-bbfd3dea-0553-49dc-b37d-c875028b77c8\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbfd3dea-0553-49dc-b37d-c875028b77c8')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-bbfd3dea-0553-49dc-b37d-c875028b77c8 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Unnamed: 0  order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "0    22678753   2392060        2604                  7          0    51072   \n",
       "1    13346427   1408550       34243                  1          1    25449   \n",
       "2    22925325   2418006       21616                 35          1   138390   \n",
       "3    17216127   1816124       43209                  3          0    42441   \n",
       "4    30363018   3202917       43368                  2          0    81257   \n",
       "\n",
       "  eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0    prior            35          6                 11   \n",
       "1    prior            14          6                 11   \n",
       "2    prior            12          0                 15   \n",
       "3    prior             1          6                 10   \n",
       "4    prior            14          5                 12   \n",
       "\n",
       "   days_since_prior_order                     product_name  aisle_id  \\\n",
       "0                     3.0              Lemon Zest Sorbetto        37   \n",
       "1                     1.0            Organic Baby Broccoli        83   \n",
       "2                    30.0             Organic Baby Arugula       123   \n",
       "3                     NaN                       Large Eggs        86   \n",
       "4                     3.0  Wild Salmon Florentine Cat Food        41   \n",
       "\n",
       "   department_id                       aisle  department  \n",
       "0              1               ice cream ice      frozen  \n",
       "1              4            fresh vegetables     produce  \n",
       "2              4  packaged vegetables fruits     produce  \n",
       "3             16                        eggs  dairy eggs  \n",
       "4              8               cat food care        pets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('/content/drive/MyDrive/Retail/sample_merged.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xrwSZKz1YLmX"
   },
   "outputs": [],
   "source": [
    "# Filter for add_to_cart_order < 5\n",
    "df = data[data['add_to_cart_order'] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvr37Yj3Yky8",
    "outputId": "3f8e6dae-db89-4c22-d2cd-6f251ab6a111"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-5ea03488ce44>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['user_idx'] = df['user_id'].map(user_map)\n",
      "<ipython-input-5-5ea03488ce44>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['product_idx'] = df['product_id'].map(product_map)\n"
     ]
    }
   ],
   "source": [
    "# Encode users and products to integer indices for matrix representation\n",
    "user_ids = df['user_id'].unique()\n",
    "product_ids = df['product_id'].unique()\n",
    "user_map = {id: idx for idx, id in enumerate(user_ids)}\n",
    "product_map = {id: idx for idx, id in enumerate(product_ids)}\n",
    "df['user_idx'] = df['user_id'].map(user_map)\n",
    "df['product_idx'] = df['product_id'].map(product_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eh-VVG-kYnbz",
    "outputId": "40001089-2f89-4cb8-b048-60abe4dfc4d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    0\n",
       " 3    1\n",
       " 4    2\n",
       " 5    3\n",
       " 8    4\n",
       " Name: user_idx, dtype: int64,\n",
       " 1    0\n",
       " 3    1\n",
       " 4    2\n",
       " 5    3\n",
       " 8    4\n",
       " Name: product_idx, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_idx'].head(),df['product_idx'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iryQMvjQYpUL",
    "outputId": "c26489b0-5c5c-4825-f147-abfbed59bf18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2517.5685995844115\n",
      "Epoch 2/50, Loss: 2507.2105754185473\n",
      "Epoch 3/50, Loss: 2496.7754856187044\n",
      "Epoch 4/50, Loss: 2486.1967239992896\n",
      "Epoch 5/50, Loss: 2475.407369513135\n",
      "Epoch 6/50, Loss: 2464.339662100563\n",
      "Epoch 7/50, Loss: 2452.9245835024235\n",
      "Epoch 8/50, Loss: 2441.0915673281256\n",
      "Epoch 9/50, Loss: 2428.768374371203\n",
      "Epoch 10/50, Loss: 2415.8811811980972\n",
      "Epoch 11/50, Loss: 2402.354941040727\n",
      "Epoch 12/50, Loss: 2388.1140834932526\n",
      "Epoch 13/50, Loss: 2373.0836194687677\n",
      "Epoch 14/50, Loss: 2357.1907047432314\n",
      "Epoch 15/50, Loss: 2340.366682434293\n",
      "Epoch 16/50, Loss: 2322.5495653117305\n",
      "Epoch 17/50, Loss: 2303.6868291694936\n",
      "Epoch 18/50, Loss: 2283.7382720030937\n",
      "Epoch 19/50, Loss: 2262.678566073459\n",
      "Epoch 20/50, Loss: 2240.499022832662\n",
      "Epoch 21/50, Loss: 2217.2080508210743\n",
      "Epoch 22/50, Loss: 2192.8298653113497\n",
      "Epoch 23/50, Loss: 2167.401240254111\n",
      "Epoch 24/50, Loss: 2140.9664684070235\n",
      "Epoch 25/50, Loss: 2113.5711407988374\n",
      "Epoch 26/50, Loss: 2085.2557401705158\n",
      "Epoch 27/50, Loss: 2056.0502170782843\n",
      "Epoch 28/50, Loss: 2025.9705854811023\n",
      "Epoch 29/50, Loss: 1995.0181490396972\n",
      "Epoch 30/50, Loss: 1963.1813795572257\n",
      "Epoch 31/50, Loss: 1930.4399088110558\n",
      "Epoch 32/50, Loss: 1896.7697352859925\n",
      "Epoch 33/50, Loss: 1862.148665305339\n",
      "Epoch 34/50, Loss: 1826.5611710456515\n",
      "Epoch 35/50, Loss: 1790.0021502773257\n",
      "Epoch 36/50, Loss: 1752.4793951541906\n",
      "Epoch 37/50, Loss: 1714.0148336856953\n",
      "Epoch 38/50, Loss: 1674.644761332974\n",
      "Epoch 39/50, Loss: 1634.4193367697073\n",
      "Epoch 40/50, Loss: 1593.401602772657\n",
      "Epoch 41/50, Loss: 1551.6662423953846\n",
      "Epoch 42/50, Loss: 1509.2982178684945\n",
      "Epoch 43/50, Loss: 1466.391381436262\n",
      "Epoch 44/50, Loss: 1423.0471015298572\n",
      "Epoch 45/50, Loss: 1379.372916440149\n",
      "Epoch 46/50, Loss: 1335.4812098701436\n",
      "Epoch 47/50, Loss: 1291.4878958212707\n",
      "Epoch 48/50, Loss: 1247.511101169952\n",
      "Epoch 49/50, Loss: 1203.6698400979146\n",
      "Epoch 50/50, Loss: 1160.0826826952978\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "n_users, n_items = len(user_ids), len(product_ids)\n",
    "n_factors = 10  # Number of latent factors\n",
    "lr = 0.01  # Learning rate\n",
    "n_epochs = 50  # Number of training epochs\n",
    "reg = 0.01  # Regularization term to prevent overfitting\n",
    "\n",
    "# Initialize user and item matrices with random values\n",
    "user_matrix = np.random.normal(scale=1./n_factors, size=(n_users, n_factors))\n",
    "item_matrix = np.random.normal(scale=1./n_factors, size=(n_items, n_factors))\n",
    "\n",
    "# Training with Stochastic Gradient Descent (SGD)\n",
    "for epoch in range(n_epochs):\n",
    "    for _, row in df.iterrows():\n",
    "        u = row['user_idx']\n",
    "        i = row['product_idx']\n",
    "        rating = row['add_to_cart_order']\n",
    "\n",
    "        # Predicted rating\n",
    "        pred = np.dot(user_matrix[u], item_matrix[i])\n",
    "\n",
    "        # Error\n",
    "        error = rating - pred\n",
    "\n",
    "        # Update user and item latent factors\n",
    "        user_matrix[u] += lr * (error * item_matrix[i] - reg * user_matrix[u])\n",
    "        item_matrix[i] += lr * (error * user_matrix[u] - reg * item_matrix[i])\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = 0\n",
    "    for _, row in df.iterrows():\n",
    "        u = row['user_idx']\n",
    "        i = row['product_idx']\n",
    "        rating = row['add_to_cart_order']\n",
    "        pred = np.dot(user_matrix[u], item_matrix[i])\n",
    "        loss += (rating - pred) ** 2 + reg * (np.linalg.norm(user_matrix[u]) + np.linalg.norm(item_matrix[i]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BLJujmxYrRW",
    "outputId": "11016ee2-b184-4f5f-989a-e73bebd876e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (user 41658 for product 9550): User or product not found.\n",
      "Top recommendations for user 41658: User not found.\n"
     ]
    }
   ],
   "source": [
    "# Function to predict for a given user and product\n",
    "def predict(user_id, product_id):\n",
    "    u = user_map.get(user_id)\n",
    "    i = product_map.get(product_id)\n",
    "    if u is None or i is None:\n",
    "        return \"User or product not found.\"\n",
    "    return np.dot(user_matrix[u], item_matrix[i])\n",
    "\n",
    "# Example prediction for a specific user and product\n",
    "user_id = 41658\n",
    "product_id = 9550\n",
    "prediction = predict(user_id, product_id)\n",
    "print(f\"Prediction (user {user_id} for product {product_id}): {prediction}\")\n",
    "\n",
    "# Generate recommendations\n",
    "def recommend(user_id, n_recommendations=5):\n",
    "    u = user_map.get(user_id)\n",
    "    if u is None:\n",
    "        return \"User not found.\"\n",
    "    scores = np.dot(user_matrix[u], item_matrix.T)\n",
    "    product_indices = np.argsort(-scores)[:n_recommendations]\n",
    "    recommended_products = [product_ids[i] for i in product_indices]\n",
    "    return recommended_products\n",
    "\n",
    "# Example recommendation for a specific user\n",
    "user_id = 41658\n",
    "recommendations = recommend(user_id, n_recommendations=3)\n",
    "print(f\"Top recommendations for user {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76pKPfoTYvQZ",
    "outputId": "9681382a-9bf3-452e-838a-266d6d58e98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 127.9556\n",
      "Epoch 2/20, Loss: 127.4126\n",
      "Epoch 3/20, Loss: 126.7051\n",
      "Epoch 4/20, Loss: 125.5683\n",
      "Epoch 5/20, Loss: 123.4545\n",
      "Epoch 6/20, Loss: 119.3356\n",
      "Epoch 7/20, Loss: 112.6704\n",
      "Epoch 8/20, Loss: 105.1877\n",
      "Epoch 9/20, Loss: 96.2691\n",
      "Epoch 10/20, Loss: 86.2895\n",
      "Epoch 11/20, Loss: 76.2942\n",
      "Epoch 12/20, Loss: 67.0055\n",
      "Epoch 13/20, Loss: 58.5854\n",
      "Epoch 14/20, Loss: 51.0903\n",
      "Epoch 15/20, Loss: 44.5582\n",
      "Epoch 16/20, Loss: 38.9188\n",
      "Epoch 17/20, Loss: 34.0589\n",
      "Epoch 18/20, Loss: 29.8728\n",
      "Epoch 19/20, Loss: 26.2685\n",
      "Epoch 20/20, Loss: 23.1628\n",
      "Tuning params: Factors=10, LR=0.01, Reg=0.01, Final MSE=23.1628\n",
      "Epoch 1/20, Loss: 127.9285\n",
      "Epoch 2/20, Loss: 127.3740\n",
      "Epoch 3/20, Loss: 126.6169\n",
      "Epoch 4/20, Loss: 125.3244\n",
      "Epoch 5/20, Loss: 122.7924\n",
      "Epoch 6/20, Loss: 118.1259\n",
      "Epoch 7/20, Loss: 112.2344\n",
      "Epoch 8/20, Loss: 104.9623\n",
      "Epoch 9/20, Loss: 95.3905\n",
      "Epoch 10/20, Loss: 84.9546\n",
      "Epoch 11/20, Loss: 75.3264\n",
      "Epoch 12/20, Loss: 66.8538\n",
      "Epoch 13/20, Loss: 59.1155\n",
      "Epoch 14/20, Loss: 51.9351\n",
      "Epoch 15/20, Loss: 45.4237\n",
      "Epoch 16/20, Loss: 39.6791\n",
      "Epoch 17/20, Loss: 34.6861\n",
      "Epoch 18/20, Loss: 30.3717\n",
      "Epoch 19/20, Loss: 26.6555\n",
      "Epoch 20/20, Loss: 23.4613\n",
      "Tuning params: Factors=10, LR=0.01, Reg=0.02, Final MSE=23.4613\n",
      "Epoch 1/20, Loss: 127.9308\n",
      "Epoch 2/20, Loss: 127.3804\n",
      "Epoch 3/20, Loss: 126.6409\n",
      "Epoch 4/20, Loss: 125.3917\n",
      "Epoch 5/20, Loss: 122.9530\n",
      "Epoch 6/20, Loss: 118.3434\n",
      "Epoch 7/20, Loss: 112.2362\n",
      "Epoch 8/20, Loss: 105.2348\n",
      "Epoch 9/20, Loss: 96.3904\n",
      "Epoch 10/20, Loss: 86.5119\n",
      "Epoch 11/20, Loss: 76.6846\n",
      "Epoch 12/20, Loss: 67.6248\n",
      "Epoch 13/20, Loss: 59.4394\n",
      "Epoch 14/20, Loss: 52.0397\n",
      "Epoch 15/20, Loss: 45.4240\n",
      "Epoch 16/20, Loss: 39.6315\n",
      "Epoch 17/20, Loss: 34.6422\n",
      "Epoch 18/20, Loss: 30.3642\n",
      "Epoch 19/20, Loss: 26.6797\n",
      "Epoch 20/20, Loss: 23.4900\n",
      "Tuning params: Factors=10, LR=0.01, Reg=0.05, Final MSE=23.4900\n",
      "Epoch 1/20, Loss: 127.9633\n",
      "Epoch 2/20, Loss: 127.6984\n",
      "Epoch 3/20, Loss: 127.4184\n",
      "Epoch 4/20, Loss: 127.1033\n",
      "Epoch 5/20, Loss: 126.7278\n",
      "Epoch 6/20, Loss: 126.2573\n",
      "Epoch 7/20, Loss: 125.6421\n",
      "Epoch 8/20, Loss: 124.8090\n",
      "Epoch 9/20, Loss: 123.6528\n",
      "Epoch 10/20, Loss: 122.0375\n",
      "Epoch 11/20, Loss: 119.8322\n",
      "Epoch 12/20, Loss: 117.0074\n",
      "Epoch 13/20, Loss: 113.7189\n",
      "Epoch 14/20, Loss: 110.1563\n",
      "Epoch 15/20, Loss: 106.2910\n",
      "Epoch 16/20, Loss: 102.0082\n",
      "Epoch 17/20, Loss: 97.3371\n",
      "Epoch 18/20, Loss: 92.4220\n",
      "Epoch 19/20, Loss: 87.4282\n",
      "Epoch 20/20, Loss: 82.4887\n",
      "Tuning params: Factors=10, LR=0.005, Reg=0.01, Final MSE=82.4887\n",
      "Epoch 1/20, Loss: 127.9368\n",
      "Epoch 2/20, Loss: 127.6701\n",
      "Epoch 3/20, Loss: 127.3837\n",
      "Epoch 4/20, Loss: 127.0536\n",
      "Epoch 5/20, Loss: 126.6486\n",
      "Epoch 6/20, Loss: 126.1246\n",
      "Epoch 7/20, Loss: 125.4169\n",
      "Epoch 8/20, Loss: 124.4312\n",
      "Epoch 9/20, Loss: 123.0436\n",
      "Epoch 10/20, Loss: 121.1320\n",
      "Epoch 11/20, Loss: 118.6659\n",
      "Epoch 12/20, Loss: 115.7918\n",
      "Epoch 13/20, Loss: 112.6969\n",
      "Epoch 14/20, Loss: 109.3400\n",
      "Epoch 15/20, Loss: 105.5583\n",
      "Epoch 16/20, Loss: 101.3240\n",
      "Epoch 17/20, Loss: 96.7413\n",
      "Epoch 18/20, Loss: 91.9548\n",
      "Epoch 19/20, Loss: 87.0963\n",
      "Epoch 20/20, Loss: 82.2707\n",
      "Tuning params: Factors=10, LR=0.005, Reg=0.02, Final MSE=82.2707\n",
      "Epoch 1/20, Loss: 127.9518\n",
      "Epoch 2/20, Loss: 127.7052\n",
      "Epoch 3/20, Loss: 127.4422\n",
      "Epoch 4/20, Loss: 127.1429\n",
      "Epoch 5/20, Loss: 126.7811\n",
      "Epoch 6/20, Loss: 126.3200\n",
      "Epoch 7/20, Loss: 125.7049\n",
      "Epoch 8/20, Loss: 124.8549\n",
      "Epoch 9/20, Loss: 123.6582\n",
      "Epoch 10/20, Loss: 121.9890\n",
      "Epoch 11/20, Loss: 119.7768\n",
      "Epoch 12/20, Loss: 117.1088\n",
      "Epoch 13/20, Loss: 114.1818\n",
      "Epoch 14/20, Loss: 111.0201\n",
      "Epoch 15/20, Loss: 107.4386\n",
      "Epoch 16/20, Loss: 103.3347\n",
      "Epoch 17/20, Loss: 98.7868\n",
      "Epoch 18/20, Loss: 93.9715\n",
      "Epoch 19/20, Loss: 89.0737\n",
      "Epoch 20/20, Loss: 84.2282\n",
      "Tuning params: Factors=10, LR=0.005, Reg=0.05, Final MSE=84.2282\n",
      "Epoch 1/20, Loss: 127.9459\n",
      "Epoch 2/20, Loss: 127.6776\n",
      "Epoch 3/20, Loss: 127.3186\n",
      "Epoch 4/20, Loss: 126.7112\n",
      "Epoch 5/20, Loss: 125.4879\n",
      "Epoch 6/20, Loss: 122.8732\n",
      "Epoch 7/20, Loss: 118.3892\n",
      "Epoch 8/20, Loss: 113.4041\n",
      "Epoch 9/20, Loss: 106.6064\n",
      "Epoch 10/20, Loss: 97.9329\n",
      "Epoch 11/20, Loss: 88.7077\n",
      "Epoch 12/20, Loss: 79.9814\n",
      "Epoch 13/20, Loss: 71.8628\n",
      "Epoch 14/20, Loss: 64.2152\n",
      "Epoch 15/20, Loss: 57.0846\n",
      "Epoch 16/20, Loss: 50.5792\n",
      "Epoch 17/20, Loss: 44.7623\n",
      "Epoch 18/20, Loss: 39.6127\n",
      "Epoch 19/20, Loss: 35.0614\n",
      "Epoch 20/20, Loss: 31.0476\n",
      "Tuning params: Factors=20, LR=0.01, Reg=0.01, Final MSE=31.0476\n",
      "Epoch 1/20, Loss: 127.9596\n",
      "Epoch 2/20, Loss: 127.7010\n",
      "Epoch 3/20, Loss: 127.3689\n",
      "Epoch 4/20, Loss: 126.8360\n",
      "Epoch 5/20, Loss: 125.8215\n",
      "Epoch 6/20, Loss: 123.6832\n",
      "Epoch 7/20, Loss: 119.5005\n",
      "Epoch 8/20, Loss: 114.0030\n",
      "Epoch 9/20, Loss: 107.4535\n",
      "Epoch 10/20, Loss: 98.9769\n",
      "Epoch 11/20, Loss: 89.7585\n",
      "Epoch 12/20, Loss: 80.8998\n",
      "Epoch 13/20, Loss: 72.6686\n",
      "Epoch 14/20, Loss: 64.8951\n",
      "Epoch 15/20, Loss: 57.5610\n",
      "Epoch 16/20, Loss: 50.7928\n",
      "Epoch 17/20, Loss: 44.7415\n",
      "Epoch 18/20, Loss: 39.4557\n",
      "Epoch 19/20, Loss: 34.8792\n",
      "Epoch 20/20, Loss: 30.9230\n",
      "Tuning params: Factors=20, LR=0.01, Reg=0.02, Final MSE=30.9230\n",
      "Epoch 1/20, Loss: 127.9503\n",
      "Epoch 2/20, Loss: 127.6857\n",
      "Epoch 3/20, Loss: 127.3446\n",
      "Epoch 4/20, Loss: 126.8018\n",
      "Epoch 5/20, Loss: 125.7930\n",
      "Epoch 6/20, Loss: 123.7198\n",
      "Epoch 7/20, Loss: 119.5484\n",
      "Epoch 8/20, Loss: 113.3751\n",
      "Epoch 9/20, Loss: 106.5216\n",
      "Epoch 10/20, Loss: 98.0983\n",
      "Epoch 11/20, Loss: 88.9675\n",
      "Epoch 12/20, Loss: 80.0013\n",
      "Epoch 13/20, Loss: 71.7036\n",
      "Epoch 14/20, Loss: 64.1225\n",
      "Epoch 15/20, Loss: 57.1182\n",
      "Epoch 16/20, Loss: 50.7023\n",
      "Epoch 17/20, Loss: 44.9371\n",
      "Epoch 18/20, Loss: 39.8111\n",
      "Epoch 19/20, Loss: 35.2635\n",
      "Epoch 20/20, Loss: 31.2413\n",
      "Tuning params: Factors=20, LR=0.01, Reg=0.05, Final MSE=31.2413\n",
      "Epoch 1/20, Loss: 127.9278\n",
      "Epoch 2/20, Loss: 127.7936\n",
      "Epoch 3/20, Loss: 127.6481\n",
      "Epoch 4/20, Loss: 127.4791\n",
      "Epoch 5/20, Loss: 127.2700\n",
      "Epoch 6/20, Loss: 126.9960\n",
      "Epoch 7/20, Loss: 126.6191\n",
      "Epoch 8/20, Loss: 126.0804\n",
      "Epoch 9/20, Loss: 125.2926\n",
      "Epoch 10/20, Loss: 124.1449\n",
      "Epoch 11/20, Loss: 122.5460\n",
      "Epoch 12/20, Loss: 120.5224\n",
      "Epoch 13/20, Loss: 118.2615\n",
      "Epoch 14/20, Loss: 115.8947\n",
      "Epoch 15/20, Loss: 113.2779\n",
      "Epoch 16/20, Loss: 110.1997\n",
      "Epoch 17/20, Loss: 106.5995\n",
      "Epoch 18/20, Loss: 102.5458\n",
      "Epoch 19/20, Loss: 98.1703\n",
      "Epoch 20/20, Loss: 93.6254\n",
      "Tuning params: Factors=20, LR=0.005, Reg=0.01, Final MSE=93.6254\n",
      "Epoch 1/20, Loss: 127.9379\n",
      "Epoch 2/20, Loss: 127.8051\n",
      "Epoch 3/20, Loss: 127.6617\n",
      "Epoch 4/20, Loss: 127.4963\n",
      "Epoch 5/20, Loss: 127.2936\n",
      "Epoch 6/20, Loss: 127.0322\n",
      "Epoch 7/20, Loss: 126.6795\n",
      "Epoch 8/20, Loss: 126.1852\n",
      "Epoch 9/20, Loss: 125.4733\n",
      "Epoch 10/20, Loss: 124.4364\n",
      "Epoch 11/20, Loss: 122.9501\n",
      "Epoch 12/20, Loss: 120.9383\n",
      "Epoch 13/20, Loss: 118.4789\n",
      "Epoch 14/20, Loss: 115.7776\n",
      "Epoch 15/20, Loss: 112.8932\n",
      "Epoch 16/20, Loss: 109.6642\n",
      "Epoch 17/20, Loss: 105.9878\n",
      "Epoch 18/20, Loss: 101.9257\n",
      "Epoch 19/20, Loss: 97.6225\n",
      "Epoch 20/20, Loss: 93.2304\n",
      "Tuning params: Factors=20, LR=0.005, Reg=0.02, Final MSE=93.2304\n",
      "Epoch 1/20, Loss: 127.9216\n",
      "Epoch 2/20, Loss: 127.7888\n",
      "Epoch 3/20, Loss: 127.6444\n",
      "Epoch 4/20, Loss: 127.4770\n",
      "Epoch 5/20, Loss: 127.2713\n",
      "Epoch 6/20, Loss: 127.0050\n",
      "Epoch 7/20, Loss: 126.6439\n",
      "Epoch 8/20, Loss: 126.1355\n",
      "Epoch 9/20, Loss: 125.4001\n",
      "Epoch 10/20, Loss: 124.3288\n",
      "Epoch 11/20, Loss: 122.8067\n",
      "Epoch 12/20, Loss: 120.7925\n",
      "Epoch 13/20, Loss: 118.4119\n",
      "Epoch 14/20, Loss: 115.8602\n",
      "Epoch 15/20, Loss: 113.1151\n",
      "Epoch 16/20, Loss: 109.9787\n",
      "Epoch 17/20, Loss: 106.3588\n",
      "Epoch 18/20, Loss: 102.3133\n",
      "Epoch 19/20, Loss: 97.9686\n",
      "Epoch 20/20, Loss: 93.4644\n",
      "Tuning params: Factors=20, LR=0.005, Reg=0.05, Final MSE=93.4644\n",
      "Epoch 1/20, Loss: 127.9447\n",
      "Epoch 2/20, Loss: 127.7666\n",
      "Epoch 3/20, Loss: 127.5299\n",
      "Epoch 4/20, Loss: 127.1365\n",
      "Epoch 5/20, Loss: 126.3566\n",
      "Epoch 6/20, Loss: 124.6392\n",
      "Epoch 7/20, Loss: 121.1266\n",
      "Epoch 8/20, Loss: 116.4410\n",
      "Epoch 9/20, Loss: 111.1358\n",
      "Epoch 10/20, Loss: 103.8776\n",
      "Epoch 11/20, Loss: 95.2726\n",
      "Epoch 12/20, Loss: 86.3562\n",
      "Epoch 13/20, Loss: 78.0771\n",
      "Epoch 14/20, Loss: 70.5701\n",
      "Epoch 15/20, Loss: 63.5184\n",
      "Epoch 16/20, Loss: 56.8146\n",
      "Epoch 17/20, Loss: 50.6040\n",
      "Epoch 18/20, Loss: 45.0327\n",
      "Epoch 19/20, Loss: 40.1227\n",
      "Epoch 20/20, Loss: 35.8068\n",
      "Tuning params: Factors=30, LR=0.01, Reg=0.01, Final MSE=35.8068\n",
      "Epoch 1/20, Loss: 127.9365\n",
      "Epoch 2/20, Loss: 127.7552\n",
      "Epoch 3/20, Loss: 127.5113\n",
      "Epoch 4/20, Loss: 127.0987\n",
      "Epoch 5/20, Loss: 126.2648\n",
      "Epoch 6/20, Loss: 124.4134\n",
      "Epoch 7/20, Loss: 120.7523\n",
      "Epoch 8/20, Loss: 116.2425\n",
      "Epoch 9/20, Loss: 110.9159\n",
      "Epoch 10/20, Loss: 103.5596\n",
      "Epoch 11/20, Loss: 94.8502\n",
      "Epoch 12/20, Loss: 86.0337\n",
      "Epoch 13/20, Loss: 77.9184\n",
      "Epoch 14/20, Loss: 70.3963\n",
      "Epoch 15/20, Loss: 63.2346\n",
      "Epoch 16/20, Loss: 56.4556\n",
      "Epoch 17/20, Loss: 50.2455\n",
      "Epoch 18/20, Loss: 44.7308\n",
      "Epoch 19/20, Loss: 39.8940\n",
      "Epoch 20/20, Loss: 35.6432\n",
      "Tuning params: Factors=30, LR=0.01, Reg=0.02, Final MSE=35.6432\n",
      "Epoch 1/20, Loss: 127.9391\n",
      "Epoch 2/20, Loss: 127.7598\n",
      "Epoch 3/20, Loss: 127.5186\n",
      "Epoch 4/20, Loss: 127.1092\n",
      "Epoch 5/20, Loss: 126.2783\n",
      "Epoch 6/20, Loss: 124.4276\n",
      "Epoch 7/20, Loss: 120.7639\n",
      "Epoch 8/20, Loss: 116.2504\n",
      "Epoch 9/20, Loss: 110.9573\n",
      "Epoch 10/20, Loss: 103.7678\n",
      "Epoch 11/20, Loss: 95.3181\n",
      "Epoch 12/20, Loss: 86.6382\n",
      "Epoch 13/20, Loss: 78.4881\n",
      "Epoch 14/20, Loss: 70.8997\n",
      "Epoch 15/20, Loss: 63.7282\n",
      "Epoch 16/20, Loss: 56.9974\n",
      "Epoch 17/20, Loss: 50.8223\n",
      "Epoch 18/20, Loss: 45.2928\n",
      "Epoch 19/20, Loss: 40.4094\n",
      "Epoch 20/20, Loss: 36.0989\n",
      "Tuning params: Factors=30, LR=0.01, Reg=0.05, Final MSE=36.0989\n",
      "Epoch 1/20, Loss: 127.9421\n",
      "Epoch 2/20, Loss: 127.8525\n",
      "Epoch 3/20, Loss: 127.7558\n",
      "Epoch 4/20, Loss: 127.6435\n",
      "Epoch 5/20, Loss: 127.5043\n",
      "Epoch 6/20, Loss: 127.3209\n",
      "Epoch 7/20, Loss: 127.0666\n",
      "Epoch 8/20, Loss: 126.6987\n",
      "Epoch 9/20, Loss: 126.1507\n",
      "Epoch 10/20, Loss: 125.3286\n",
      "Epoch 11/20, Loss: 124.1291\n",
      "Epoch 12/20, Loss: 122.5090\n",
      "Epoch 13/20, Loss: 120.5835\n",
      "Epoch 14/20, Loss: 118.5620\n",
      "Epoch 15/20, Loss: 116.4523\n",
      "Epoch 16/20, Loss: 114.0278\n",
      "Epoch 17/20, Loss: 111.1188\n",
      "Epoch 18/20, Loss: 107.7139\n",
      "Epoch 19/20, Loss: 103.9042\n",
      "Epoch 20/20, Loss: 99.8276\n",
      "Tuning params: Factors=30, LR=0.005, Reg=0.01, Final MSE=99.8276\n",
      "Epoch 1/20, Loss: 127.9406\n",
      "Epoch 2/20, Loss: 127.8551\n",
      "Epoch 3/20, Loss: 127.7632\n",
      "Epoch 4/20, Loss: 127.6581\n",
      "Epoch 5/20, Loss: 127.5306\n",
      "Epoch 6/20, Loss: 127.3673\n",
      "Epoch 7/20, Loss: 127.1482\n",
      "Epoch 8/20, Loss: 126.8416\n",
      "Epoch 9/20, Loss: 126.3975\n",
      "Epoch 10/20, Loss: 125.7399\n",
      "Epoch 11/20, Loss: 124.7646\n",
      "Epoch 12/20, Loss: 123.3657\n",
      "Epoch 13/20, Loss: 121.5173\n",
      "Epoch 14/20, Loss: 119.3611\n",
      "Epoch 15/20, Loss: 117.0875\n",
      "Epoch 16/20, Loss: 114.6471\n",
      "Epoch 17/20, Loss: 111.8158\n",
      "Epoch 18/20, Loss: 108.4755\n",
      "Epoch 19/20, Loss: 104.6603\n",
      "Epoch 20/20, Loss: 100.4934\n",
      "Tuning params: Factors=30, LR=0.005, Reg=0.02, Final MSE=100.4934\n",
      "Epoch 1/20, Loss: 127.9378\n",
      "Epoch 2/20, Loss: 127.8504\n",
      "Epoch 3/20, Loss: 127.7566\n",
      "Epoch 4/20, Loss: 127.6491\n",
      "Epoch 5/20, Loss: 127.5183\n",
      "Epoch 6/20, Loss: 127.3509\n",
      "Epoch 7/20, Loss: 127.1266\n",
      "Epoch 8/20, Loss: 126.8140\n",
      "Epoch 9/20, Loss: 126.3635\n",
      "Epoch 10/20, Loss: 125.6996\n",
      "Epoch 11/20, Loss: 124.7169\n",
      "Epoch 12/20, Loss: 123.3000\n",
      "Epoch 13/20, Loss: 121.3974\n",
      "Epoch 14/20, Loss: 119.1222\n",
      "Epoch 15/20, Loss: 116.6853\n",
      "Epoch 16/20, Loss: 114.1077\n",
      "Epoch 17/20, Loss: 111.2037\n",
      "Epoch 18/20, Loss: 107.8576\n",
      "Epoch 19/20, Loss: 104.0967\n",
      "Epoch 20/20, Loss: 100.0297\n",
      "Tuning params: Factors=30, LR=0.005, Reg=0.05, Final MSE=100.0297\n",
      "Epoch 1/20, Loss: 127.9417\n",
      "Epoch 2/20, Loss: 127.8072\n",
      "Epoch 3/20, Loss: 127.6261\n",
      "Epoch 4/20, Loss: 127.3168\n",
      "Epoch 5/20, Loss: 126.6814\n",
      "Epoch 6/20, Loss: 125.2294\n",
      "Epoch 7/20, Loss: 122.1580\n",
      "Epoch 8/20, Loss: 118.0370\n",
      "Epoch 9/20, Loss: 113.6624\n",
      "Epoch 10/20, Loss: 107.4122\n",
      "Epoch 11/20, Loss: 99.4693\n",
      "Epoch 12/20, Loss: 90.8344\n",
      "Epoch 13/20, Loss: 82.6865\n",
      "Epoch 14/20, Loss: 75.2266\n",
      "Epoch 15/20, Loss: 68.2035\n",
      "Epoch 16/20, Loss: 61.5327\n",
      "Epoch 17/20, Loss: 55.2923\n",
      "Epoch 18/20, Loss: 49.5910\n",
      "Epoch 19/20, Loss: 44.4588\n",
      "Epoch 20/20, Loss: 39.8568\n",
      "Tuning params: Factors=40, LR=0.01, Reg=0.01, Final MSE=39.8568\n",
      "Epoch 1/20, Loss: 127.9372\n",
      "Epoch 2/20, Loss: 127.7988\n",
      "Epoch 3/20, Loss: 127.6127\n",
      "Epoch 4/20, Loss: 127.3010\n",
      "Epoch 5/20, Loss: 126.6834\n",
      "Epoch 6/20, Loss: 125.3172\n",
      "Epoch 7/20, Loss: 122.3454\n",
      "Epoch 8/20, Loss: 117.6824\n",
      "Epoch 9/20, Loss: 112.7749\n",
      "Epoch 10/20, Loss: 106.2362\n",
      "Epoch 11/20, Loss: 98.2888\n",
      "Epoch 12/20, Loss: 89.9480\n",
      "Epoch 13/20, Loss: 82.0380\n",
      "Epoch 14/20, Loss: 74.7176\n",
      "Epoch 15/20, Loss: 67.7531\n",
      "Epoch 16/20, Loss: 61.0234\n",
      "Epoch 17/20, Loss: 54.6924\n",
      "Epoch 18/20, Loss: 48.9528\n",
      "Epoch 19/20, Loss: 43.8476\n",
      "Epoch 20/20, Loss: 39.3118\n",
      "Tuning params: Factors=40, LR=0.01, Reg=0.02, Final MSE=39.3118\n",
      "Epoch 1/20, Loss: 127.9434\n",
      "Epoch 2/20, Loss: 127.8103\n",
      "Epoch 3/20, Loss: 127.6356\n",
      "Epoch 4/20, Loss: 127.3483\n",
      "Epoch 5/20, Loss: 126.7839\n",
      "Epoch 6/20, Loss: 125.5312\n",
      "Epoch 7/20, Loss: 122.7798\n",
      "Epoch 8/20, Loss: 118.4405\n",
      "Epoch 9/20, Loss: 113.8285\n",
      "Epoch 10/20, Loss: 107.4195\n",
      "Epoch 11/20, Loss: 99.5111\n",
      "Epoch 12/20, Loss: 91.1608\n",
      "Epoch 13/20, Loss: 83.1492\n",
      "Epoch 14/20, Loss: 75.6044\n",
      "Epoch 15/20, Loss: 68.4387\n",
      "Epoch 16/20, Loss: 61.6199\n",
      "Epoch 17/20, Loss: 55.2422\n",
      "Epoch 18/20, Loss: 49.4725\n",
      "Epoch 19/20, Loss: 44.3744\n",
      "Epoch 20/20, Loss: 39.8684\n",
      "Tuning params: Factors=40, LR=0.01, Reg=0.05, Final MSE=39.8684\n",
      "Epoch 1/20, Loss: 127.9402\n",
      "Epoch 2/20, Loss: 127.8750\n",
      "Epoch 3/20, Loss: 127.8047\n",
      "Epoch 4/20, Loss: 127.7237\n",
      "Epoch 5/20, Loss: 127.6244\n",
      "Epoch 6/20, Loss: 127.4956\n",
      "Epoch 7/20, Loss: 127.3201\n",
      "Epoch 8/20, Loss: 127.0702\n",
      "Epoch 9/20, Loss: 126.7015\n",
      "Epoch 10/20, Loss: 126.1451\n",
      "Epoch 11/20, Loss: 125.3045\n",
      "Epoch 12/20, Loss: 124.0772\n",
      "Epoch 13/20, Loss: 122.4298\n",
      "Epoch 14/20, Loss: 120.4945\n",
      "Epoch 15/20, Loss: 118.4844\n",
      "Epoch 16/20, Loss: 116.3986\n",
      "Epoch 17/20, Loss: 114.0253\n",
      "Epoch 18/20, Loss: 111.2203\n",
      "Epoch 19/20, Loss: 107.9694\n",
      "Epoch 20/20, Loss: 104.3265\n",
      "Tuning params: Factors=40, LR=0.005, Reg=0.01, Final MSE=104.3265\n",
      "Epoch 1/20, Loss: 127.9384\n",
      "Epoch 2/20, Loss: 127.8742\n",
      "Epoch 3/20, Loss: 127.8052\n",
      "Epoch 4/20, Loss: 127.7261\n",
      "Epoch 5/20, Loss: 127.6300\n",
      "Epoch 6/20, Loss: 127.5067\n",
      "Epoch 7/20, Loss: 127.3407\n",
      "Epoch 8/20, Loss: 127.1074\n",
      "Epoch 9/20, Loss: 126.7672\n",
      "Epoch 10/20, Loss: 126.2583\n",
      "Epoch 11/20, Loss: 125.4902\n",
      "Epoch 12/20, Loss: 124.3561\n",
      "Epoch 13/20, Loss: 122.7904\n",
      "Epoch 14/20, Loss: 120.8716\n",
      "Epoch 15/20, Loss: 118.8119\n",
      "Epoch 16/20, Loss: 116.6837\n",
      "Epoch 17/20, Loss: 114.2957\n",
      "Epoch 18/20, Loss: 111.4589\n",
      "Epoch 19/20, Loss: 108.1324\n",
      "Epoch 20/20, Loss: 104.3766\n",
      "Tuning params: Factors=40, LR=0.005, Reg=0.02, Final MSE=104.3766\n",
      "Epoch 1/20, Loss: 127.9401\n",
      "Epoch 2/20, Loss: 127.8751\n",
      "Epoch 3/20, Loss: 127.8055\n",
      "Epoch 4/20, Loss: 127.7259\n",
      "Epoch 5/20, Loss: 127.6295\n",
      "Epoch 6/20, Loss: 127.5067\n",
      "Epoch 7/20, Loss: 127.3428\n",
      "Epoch 8/20, Loss: 127.1149\n",
      "Epoch 9/20, Loss: 126.7862\n",
      "Epoch 10/20, Loss: 126.2990\n",
      "Epoch 11/20, Loss: 125.5676\n",
      "Epoch 12/20, Loss: 124.4833\n",
      "Epoch 13/20, Loss: 122.9604\n",
      "Epoch 14/20, Loss: 121.0339\n",
      "Epoch 15/20, Loss: 118.8966\n",
      "Epoch 16/20, Loss: 116.6727\n",
      "Epoch 17/20, Loss: 114.2120\n",
      "Epoch 18/20, Loss: 111.3069\n",
      "Epoch 19/20, Loss: 107.9050\n",
      "Epoch 20/20, Loss: 104.0852\n",
      "Tuning params: Factors=40, LR=0.005, Reg=0.05, Final MSE=104.0852\n",
      "Optimal Parameters Found: {'n_factors': 10, 'lr': 0.01, 'reg': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# SGD Training Function for Matrix Factorization\n",
    "def matrix_factorization_sgd(df, user_matrix, item_matrix, n_epochs=30, lr=0.01, reg=0.02):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for _, row in df.iterrows():\n",
    "            u_idx = row['user_idx']\n",
    "            i_idx = row['product_idx']\n",
    "            actual = row['add_to_cart_order']\n",
    "\n",
    "            # Predicted score\n",
    "            pred = np.dot(user_matrix[u_idx], item_matrix[i_idx].T)\n",
    "            error = actual - pred\n",
    "\n",
    "            # Update latent factors\n",
    "            user_matrix[u_idx] += lr * (error * item_matrix[i_idx] - reg * user_matrix[u_idx])\n",
    "            item_matrix[i_idx] += lr * (error * user_matrix[u_idx] - reg * item_matrix[i_idx])\n",
    "\n",
    "            total_loss += error ** 2\n",
    "\n",
    "        mse = total_loss / len(df)\n",
    "        losses.append(mse)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {mse:.4f}\")\n",
    "\n",
    "    return user_matrix, item_matrix, losses\n",
    "\n",
    "# Prediction Function\n",
    "def predict(df, user_matrix, item_matrix):\n",
    "    \"\"\"Predict user-product interactions using trained matrices.\"\"\"\n",
    "    return [np.dot(user_matrix[row['user_idx']], item_matrix[row['product_idx']]) for _, row in df.iterrows()]\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('/content/drive/MyDrive/Retail/sample_merged.csv')\n",
    "\n",
    "# Map users and products to indices\n",
    "user_map = {id_: idx for idx, id_ in enumerate(df['user_id'].unique())}\n",
    "product_map = {id_: idx for idx, id_ in enumerate(df['product_id'].unique())}\n",
    "\n",
    "df['user_idx'] = df['user_id'].map(user_map)\n",
    "df['product_idx'] = df['product_id'].map(product_map)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "latent_factors = [10, 20, 30, 40]\n",
    "learning_rates = [0.01, 0.005]\n",
    "regularization_params = [0.01, 0.02, 0.05]\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for n_factors in latent_factors:\n",
    "    for lr in learning_rates:\n",
    "        for reg in regularization_params:\n",
    "            user_matrix = np.random.normal(scale=1./n_factors, size=(len(user_map), n_factors))\n",
    "            item_matrix = np.random.normal(scale=1./n_factors, size=(len(product_map), n_factors))\n",
    "\n",
    "            _, _, losses = matrix_factorization_sgd(df, user_matrix, item_matrix, n_epochs=20, lr=lr, reg=reg)\n",
    "            final_loss = losses[-1]\n",
    "\n",
    "            print(f\"Tuning params: Factors={n_factors}, LR={lr}, Reg={reg}, Final MSE={final_loss:.4f}\")\n",
    "            if final_loss < best_loss:\n",
    "                best_loss = final_loss\n",
    "                best_params = {'n_factors': n_factors, 'lr': lr, 'reg': reg}\n",
    "\n",
    "print(\"Optimal Parameters Found:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNDxXjuzZCQK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
